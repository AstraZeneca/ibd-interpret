{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fm813/opt/anaconda3/envs/clam/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from models.model_hierarchical_mil import HIPT_LGP_FC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Input\n",
    "Input: $[M \\times L \\times D]$ Tensor, where:\n",
    "- M: Number of (non-overlapping) $[4096 \\times 4096]$ Image regions in a WSI (On Average: 38)\n",
    "- L: Number of (non-overlapping) $[256 \\times 256]$ Image Patches in a $[4096 \\times 4096]$ Image Region (Defaullt: 256)\n",
    "- D: Embedding Dimension (Default: 384)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Example Forward Pass (with Pre-Extracted $x_{256}$ Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Patches: 196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1950, -0.2832,  0.0804,  0.0590]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[0.2955, 0.1832, 0.2635, 0.2579]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0]]),\n",
       " None,\n",
       " None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(38,256,384)\n",
    "self = HIPT_LGP_FC()\n",
    "self.forward(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Forward Pass Shape Walkthrough (with Pre-Extracted $x_{256}$ Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Input Tensor: torch.Size([38, 256, 384])\n",
      "\n",
      "2. Re-Arranging 1D-(Seq Length of # [256x256] tokens in [4096x4096] Region) Axis to be a 2D-Grid: torch.Size([38, 384, 16, 16])\n",
      "\n",
      "3. Seq length of [4096x4096] Tokens in the WSI torch.Size([38, 192])\n",
      "\n",
      "4. ViT-4K + Global Attention Pooling to get WSI-Level Embedding: torch.Size([1, 192])\n"
     ]
    }
   ],
   "source": [
    "x_256 = torch.randn(38,256,384)\n",
    "print(\"1. Input Tensor:\", x_256.shape)\n",
    "print()\n",
    "x_256 = x_256.unfold(1, 16, 16).transpose(1,2)\n",
    "print(\"2. Re-Arranging 1D-(Seq Length of # [256x256] tokens in [4096x4096] Region) Axis to be a 2D-Grid:\", x_256.shape)\n",
    "print()\n",
    "\n",
    "h_4096 = self.local_vit(x_256)\n",
    "print(\"3. Seq length of [4096x4096] Tokens in the WSI\", h_4096.shape)\n",
    "print()\n",
    "\n",
    "h_4096 = self.global_phi(h_4096)\n",
    "h_4096 = self.global_transformer(h_4096.unsqueeze(1)).squeeze(1)\n",
    "A_4096, h_4096 = self.global_attn_pool(h_4096)  \n",
    "A_4096 = torch.transpose(A_4096, 1, 0)\n",
    "A_4096 = F.softmax(A_4096, dim=1) \n",
    "h_path = torch.mm(A_4096, h_4096)\n",
    "h_WSI = self.global_rho(h_path)\n",
    "print(\"4. ViT-4K + Global Attention Pooling to get WSI-Level Embedding:\", h_WSI.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
